{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlctx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlctx.read.csv('../../../datasets/iowa_liquor/Iowa_Liquor_sales_sample_10pct.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Store Number: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      " |-- County Number: string (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Category Name: string (nullable = true)\n",
      " |-- Vendor Number: string (nullable = true)\n",
      " |-- Item Number: string (nullable = true)\n",
      " |-- Item Description: string (nullable = true)\n",
      " |-- Bottle Volume (ml): string (nullable = true)\n",
      " |-- State Bottle Cost: string (nullable = true)\n",
      " |-- State Bottle Retail: string (nullable = true)\n",
      " |-- Bottles Sold: string (nullable = true)\n",
      " |-- Sale (Dollars): string (nullable = true)\n",
      " |-- Volume Sold (Liters): string (nullable = true)\n",
      " |-- Volume Sold (Gallons): string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+--------------+\n",
      "|Store Number|      Date|Bottles Sold|Sale (Dollars)|\n",
      "+------------+----------+------------+--------------+\n",
      "|        3717|11/04/2015|          12|        $81.00|\n",
      "|        2614|03/02/2016|           2|        $41.26|\n",
      "|        2106|02/11/2016|          24|       $453.36|\n",
      "|        2501|02/03/2016|           6|        $85.50|\n",
      "|        3654|08/18/2015|          12|       $129.60|\n",
      "+------------+----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Store Number\", \"Date\", \"Bottles Sold\", \"Sale (Dollars)\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Store Number\", df[\"Store Number\"].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import udf, regexp_replace\n",
    "\n",
    "df = df.withColumn(\"Store Number\", df[\"Store Number\"].cast(\"integer\"))\\\n",
    ".withColumn(\"Sale (Dollars)\",        regexp_replace(\"Sale (Dollars)\", \"\\\\$\", \"\").cast(\"double\")) \\\n",
    ".withColumn(\"Zip Code\",              df[\"Zip Code\"].cast(\"integer\")) \\\n",
    ".withColumn(\"County Number\",         df[\"County Number\"].cast(\"integer\")) \\\n",
    ".withColumn(\"Vendor Number\",         df[\"Vendor Number\"].cast(\"integer\")) \\\n",
    ".withColumn(\"Item Number\",           df[\"Item Number\"].cast(\"integer\")) \\\n",
    ".withColumn(\"Bottle Volume (ml)\",    df[\"Bottle Volume (ml)\"].cast(\"integer\")) \\\n",
    ".withColumn(\"State Bottle Cost\",     regexp_replace(\"State Bottle Cost\", \"\\\\$\", \"\")) \\\n",
    ".withColumn(\"State Bottle Retail\",   regexp_replace(\"State Bottle Retail\", \"\\\\$\", \"\")) \\\n",
    ".withColumn(\"Bottles Sold\",          df[\"Bottles Sold\"].cast(\"integer\")) \\\n",
    ".withColumn(\"Volume Sold (Liters)\",  df[\"Volume Sold (Liters)\"].cast(\"double\")) \\\n",
    ".withColumn(\"Volume Sold (Gallons)\", df[\"Volume Sold (Gallons)\"].cast(\"double\")) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Store Number: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zip Code: integer (nullable = true)\n",
      " |-- County Number: integer (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Category Name: string (nullable = true)\n",
      " |-- Vendor Number: integer (nullable = true)\n",
      " |-- Item Number: integer (nullable = true)\n",
      " |-- Item Description: string (nullable = true)\n",
      " |-- Bottle Volume (ml): integer (nullable = true)\n",
      " |-- State Bottle Cost: string (nullable = true)\n",
      " |-- State Bottle Retail: string (nullable = true)\n",
      " |-- Bottles Sold: integer (nullable = true)\n",
      " |-- Sale (Dollars): double (nullable = true)\n",
      " |-- Volume Sold (Liters): double (nullable = true)\n",
      " |-- Volume Sold (Gallons): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+\n",
      "|Store Number|Sale (Dollars)|\n",
      "+------------+--------------+\n",
      "|        3717|          81.0|\n",
      "|        2614|         41.26|\n",
      "|        2106|        453.36|\n",
      "|        2501|          85.5|\n",
      "|        3654|         129.6|\n",
      "+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Store Number\", \"Sale (Dollars)\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "|summary|Bottle Volume (ml)|     Bottles Sold|    Sale (Dollars)|Volume Sold (Liters)|\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "|  count|            270955|           270955|            270955|              270955|\n",
      "|   mean| 924.8303408315033|9.871284899706593| 128.9023747485706|   8.981351183775748|\n",
      "| stddev|493.08848860663403|24.04091157393874|383.02736884240466|  28.913690130072464|\n",
      "|    min|                50|                1|              1.34|                 0.1|\n",
      "|    max|              6000|             2508|           36392.4|              2508.0|\n",
      "+-------+------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Bottle Volume (ml)\", \"Bottles Sold\", \"Sale (Dollars)\", \"Volume Sold (Liters)\"]).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"Bottles Sold\", \"Sale (Dollars)\", \"Bottle Volume (ml)\"]\n",
    "response = \"Volume Sold (Liters)\"\n",
    "\n",
    "X = df.rdd.map(lambda row: LabeledPoint(row[response], \n",
    "                                        [row[feature] for feature in features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(9.0, [12.0,81.0,750.0]),\n",
       " LabeledPoint(1.5, [2.0,41.26,750.0]),\n",
       " LabeledPoint(24.0, [24.0,453.36,1000.0]),\n",
       " LabeledPoint(10.5, [6.0,85.5,1750.0]),\n",
       " LabeledPoint(21.0, [12.0,129.6,1750.0])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingData, testData = X.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LinearModel = LinearRegressionWithSGD.train(trainingData, iterations=100, step=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bottles Sold', 0.0025768025681086881),\n",
       " ('Sale (Dollars)', 0.036311185894537704),\n",
       " ('Bottle Volume (ml)', 0.0055465188167585977)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(features, LinearModel.weights.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "predObserRDD = testData.map(lambda row: (float(LinearModel.predict(row.features)), row.label)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.607561304991\n",
      "Explained Variance 251.152338334\n"
     ]
    }
   ],
   "source": [
    "reg_metrics = RegressionMetrics(predObserRDD)\n",
    "print \"R2\", reg_metrics.r2\n",
    "print \"Explained Variance\", reg_metrics.explainedVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression \n",
    "\n",
    "# Let's give it the schema \n",
    "\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"PassengerId\", IntegerType()),\n",
    "    StructField(\"Survived\",    IntegerType()),\n",
    "    StructField(\"Pclass\",      IntegerType()),\n",
    "    StructField(\"Name\",        StringType()),\n",
    "    StructField(\"Sex\",         StringType()),\n",
    "    StructField(\"Age\",         DoubleType()),\n",
    "    StructField(\"SibSp\",       IntegerType()),\n",
    "    StructField(\"Parch\",       IntegerType()),\n",
    "    StructField(\"Fare\",        DoubleType()),\n",
    "    StructField(\"Embarked\",    StringType()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlctx.read.csv('../../../datasets/titanic/titanic_clean.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\"]\n",
    "response = \"Survived\"\n",
    "\n",
    "X = df.rdd.map( \n",
    "    lambda row: LabeledPoint(row[response], [row[feature] for feature in features])\n",
    ")\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "trainingData, testData = X.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegressionWithSGD.train(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', -0.99063305227512943),\n",
       " ('Age', 0.94853124126974875),\n",
       " ('SibSp', 0.21820941775786651),\n",
       " ('Parch', 0.83089895065672759)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(features, logistic.weights.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predRDD = testData.map(lambda row: (float(logistic.predict(row.features)), row.label)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area PR Curve: 0.69528311601\n",
      "Area ROC Curve: 0.501957241795\n"
     ]
    }
   ],
   "source": [
    "metrics = BinaryClassificationMetrics(predRDD)\n",
    "print \"Area PR Curve:\", metrics.areaUnderPR\n",
    "print \"Area ROC Curve:\", metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "rf_model =RandomForest.trainClassifier(trainingData, numClasses=2, numTrees=3, \n",
    "                                       categoricalFeaturesInfo={}, impurity='gini', maxDepth=4, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf_model.predict(testData.map(lambda row: row.features))\n",
    "labeslsandpreds = testData.map(lambda row: row.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 0 <= 2.0)\n",
      "     If (feature 3 <= 0.0)\n",
      "      If (feature 2 <= 0.0)\n",
      "       If (feature 0 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 0 > 1.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 0.0)\n",
      "       If (feature 2 <= 2.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 2.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 3 > 0.0)\n",
      "      If (feature 2 <= 1.0)\n",
      "       If (feature 3 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 3 > 1.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 2 > 1.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 0 > 2.0)\n",
      "     If (feature 1 <= 17.0)\n",
      "      If (feature 2 <= 1.0)\n",
      "       If (feature 2 <= 0.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 0.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 1.0)\n",
      "       If (feature 2 <= 4.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 4.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 1 > 17.0)\n",
      "      If (feature 2 <= 2.0)\n",
      "       If (feature 3 <= 1.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 3 > 1.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 2.0)\n",
      "       Predict: 1.0\n",
      "  Tree 1:\n",
      "    If (feature 1 <= 5.0)\n",
      "     If (feature 2 <= 1.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 2 > 1.0)\n",
      "      If (feature 3 <= 1.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 3 > 1.0)\n",
      "       If (feature 2 <= 3.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 3.0)\n",
      "        Predict: 0.0\n",
      "    Else (feature 1 > 5.0)\n",
      "     If (feature 0 <= 1.0)\n",
      "      If (feature 1 <= 42.0)\n",
      "       If (feature 2 <= 2.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 2.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 1 > 42.0)\n",
      "       If (feature 2 <= 0.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 0.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 0 > 1.0)\n",
      "      If (feature 3 <= 3.0)\n",
      "       If (feature 0 <= 2.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 0 > 2.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 3 > 3.0)\n",
      "       Predict: 0.0\n",
      "  Tree 2:\n",
      "    If (feature 3 <= 0.0)\n",
      "     If (feature 2 <= 2.0)\n",
      "      If (feature 1 <= 29.0)\n",
      "       If (feature 0 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 0 > 1.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 1 > 29.0)\n",
      "       If (feature 0 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 0 > 1.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 2 > 2.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 3 > 0.0)\n",
      "     If (feature 2 <= 2.0)\n",
      "      If (feature 0 <= 2.0)\n",
      "       If (feature 3 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 3 > 1.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 0 > 2.0)\n",
      "       If (feature 1 <= 5.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 5.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 2 > 2.0)\n",
      "      If (feature 1 <= 5.0)\n",
      "       If (feature 2 <= 3.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 3.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 1 > 5.0)\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print rf_model.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
