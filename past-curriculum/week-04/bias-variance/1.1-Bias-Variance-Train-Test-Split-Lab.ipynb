{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float:  left; margin: 10px;\">\n",
    "\n",
    "# Test / Train / Split\n",
    "---\n",
    "Week 4 | Lab 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-variance lab\n",
    "\n",
    "In this lab you'll explore how bias and variance changes using a dataset on college statistics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.cross_validation import cross_val_score, KFold, train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load data\n",
    "\n",
    "Choose \"Grad.Rate\" as the target variable \"Grad.Rate\" . \n",
    "\n",
    "You'll want to discard the name of the college, and for the \"Private\" variable it will have to be changed into 1s and 0s rather than yes/no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college = pd.read_csv('~/DSI-SF-5/datasets/college_stats/College.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cross-validate a linear regression predicting your target variable from the other variables\n",
    "\n",
    "Use Sklearn's implementation of [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) which will cross validate and score your model for you. \n",
    "\n",
    "Use 'neg_mean_squared_error' as your scoring method. This will cross_val_score will return the negative of the mean square error. In order to analyze the mean square error, simply multiply 'neg_mean_squared_error' by negative one.\n",
    "\n",
    "How does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a function that will iteratively predict your target from different train-test splits\n",
    "\n",
    "This will be used to calculate the bias and the variance after this.\n",
    "\n",
    "Your function should:\n",
    "\n",
    "1. Accept a model, X predictor matrix/dataframe, y target variable, and a number of random splits to do training and testing on.\n",
    "2. The output should be a dataframe that has as its first column the true values of y, and all the other columns will be corresponding predicted values of y when that row was in the testing set.\n",
    "3. It will iterate through the number of splits\n",
    "4. Create a variable that is the list of row numbers. Use this with `train_test_split` to get out randomized training rows and testing rows for each iteration.\n",
    "5. Subset your X and y into training and testing\n",
    "6. Train your model on the training X and training y\n",
    "7. Predict values of y using the testing X\n",
    "8. Add the predicted values of y to the dataframe tracking y predictions - the predicted y values should be insert in the correct row so that they match the true value of y in the first column. You can index using the test indices you got out of train_test_split to do this. (The rest of the rows that were part of the training set can be nan for that iteration).\n",
    "\n",
    "\n",
    "**NOTE: ** This function will look considerably different than the \"cross_validate\" function that I wrote in the test-train-split lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create different predictor datasets\n",
    "\n",
    "To see what happens to bias and variance as the predictors change, create a few versions of X that have different numbers of predictors in them.\n",
    "\n",
    "For example, one could have all the other variables, and another one could be predicting only using private vs. public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Use the predict function you wrote above to get the predicted values for each version of the data\n",
    "\n",
    "Run each of your X through the function with the y target vector. As you recall the output of your function has the true values of y in a column and then predicted values of y in other columns for the different train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Calculate bias and variance \n",
    "\n",
    "I've given you two functions below to calculate bias and variance if they are given the dataframe that has the first column as the true y values and the other column the predicted y values at each train/test split iteration.\n",
    "\n",
    "You can use these to calculate the bias and variance of your different predictor variables. If you have more predictors variance of prediction should generally go up and bias goes down. Likewise, if you have few predictors variance should go down and bias goes up.\n",
    "\n",
    "If you have an insanely bad model, they both might go up a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_bias_sq(yhats_df):\n",
    "    # Take out the true values of y that are in the first column:\n",
    "    ytrue = yhats_df.iloc[:,0].values\n",
    "    \n",
    "    # Calculate the mean of the predictions, averaged across the columns.\n",
    "    # So, all of the predictions for the true y at row 0 would be averaged together\n",
    "    # and so on for all the rows.\n",
    "    yhat_means = yhats_df.iloc[:,1:].mean(axis=1).values\n",
    "    \n",
    "    # Subtract the true value of y from the mean of the predicted values, and square it.\n",
    "    elementwise_bias_sq = (yhat_means - ytrue)**2\n",
    "    \n",
    "    # Take the mean of those squared bias values (across all y)\n",
    "    mean_bias_sq = np.mean(elementwise_bias_sq)\n",
    "    return mean_bias_sq\n",
    "\n",
    "\n",
    "def calculate_variance(yhats_df):\n",
    "    # Calculate the mean of the predicted y's across the columns (mean of yhat for each row)\n",
    "    yhats_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # subtract the mean of the yhats from the original yhat values (for each row)\n",
    "    # and square the result. \n",
    "    yhats_devsq = yhats_df.iloc[:,1:].subtract(yhats_means, axis=0)**2\n",
    "    \n",
    "    # Take the mean of the squared deviations from the mean, then \n",
    "    # take the mean of those to get the overall variance across the y observations\n",
    "    yhats_devsq_means = yhats_devsq.mean(axis=1).values\n",
    "    return np.mean(yhats_devsq_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "\n",
    "Plot a learning curve for each of your 3 different predictors  (ie. you should have created 3 different design matricies X, each with a different sete of predictors).\n",
    "\n",
    "Use Sklearn's built-in learning curves funciton: [learning_curve](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html#sklearn.model_selection.learning_curve)   **Yes, you should read the docs.** \n",
    "\n",
    "Sklearn's learning_curve will do two things for you:\n",
    "\n",
    "1. It will cross validate your model for you\n",
    "2. It will return: train_sizes_abs, train_scores, and test_scores which you can use to plot a learning curve\n",
    "\n",
    "\n",
    "For each of your 3 design matricies: \n",
    "\n",
    "1. Use learning_curve with these parameters:  \n",
    "\n",
    "        train_sizes=np.arange(0.1, 1.1, 0.1), \n",
    "        scoring = 'neg_mean_squared_error',\n",
    "        cv=10, \n",
    "        n_jobs=3\n",
    "        \n",
    "        Make sure you understand what each of these parameters are doing!\n",
    "    \n",
    "2. Take the sum of your train_errors and test_errors along their columns. **Explain why this makes sense!** Hint: you specified 10 CV iterations, and 10 train_size which will iterate through the training sizes for each CV instance. So you'll recieve a 10x10 matrix for each error vector from learning_curve.\n",
    "\n",
    "3. Multiply your results train_errors and test_errors from part 2 by negative one. \n",
    "\n",
    "4. Plot your learning curve and label your plot\n",
    "\n",
    "5. Make some observations about how well your model performs (i.e. underfitting, overfitting, overtraining, ...) Do the bias/variance calculates you made above provide any insight about your learning curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
