{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 15px;\">\n",
    "### DBSCAN-Code-From-Scratch\n",
    "\n",
    "\n",
    "Week **6** | Lesson **2.2**\n",
    "\n",
    "---\n",
    "| TIMING  | TYPE  \n",
    "|:-:|---|---|\n",
    "| 25 min| [Review](#review) |\n",
    "| 10 min| [**Industry Example **](#hook) |\n",
    "| 45 min| [**Content **](#content) |\n",
    "| 20 min| [Conclusion](#conclusion) |\n",
    "| 5 min | [Additional Resources](#more)\n",
    "\n",
    "---\n",
    "\n",
    "### Lesson Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Demonstrate an understanding of how DBSCAN works by coding the algorithm from scratch\n",
    "\n",
    "---\n",
    "### Student Pre-Work \n",
    "\n",
    "*Before this lesson, you should already be able to:*\n",
    "- Understand how K-Means clustering works\n",
    "- Use Matplotlib and Seaborn for ploting data\n",
    "- Go through this data visualization of [DBSCAN](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)\n",
    "\n",
    "---\n",
    "<a name=\"review\"></a>\n",
    "### Review: \n",
    "If you didn't already do so, go through this data visualization of [DBSCAN](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)\n",
    "\n",
    "\n",
    "---\n",
    "<a name=\"hook\"> </a>\n",
    "\n",
    "### Applications: \n",
    "\n",
    "[DBSCAN](https://www.oreilly.com/ideas/clustering-geolocated-data-using-spark-and-dbscan) is used to proximity cluster app users based on their spatial coordinates\n",
    "\n",
    "![](https://d3ansictanv2wj.cloudfront.net/florida.dbscan2-8797930765675ecb45d7c19406db8031.jpg)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "# **Lesson**\n",
    "<a name=\"content\"></a>\n",
    "\n",
    "## Density-based spatial clustering of applications with noise (DBSCAN)\n",
    "\n",
    "---\n",
    "\n",
    "DBSCAN is a clustering algorithm that groups datapoints together based on \"density\". Nearby points get assigned to a common cluster, and outlier points get assigned to their own clusters. DBSCAN is effective and attractive for its simplicity and minimal pre-specified parameters.\n",
    "\n",
    "There are only two parameters that need to be specified for DBSCAN:\n",
    "\n",
    "    eps : a minimum distance between points that can define a \"connection\"\n",
    "    \n",
    "    min_samples : minimum number of points that a point needs to have \n",
    "                  as neighbors to define it as a \"core sample\"\n",
    "    \n",
    "**Core samples** are by design the points that lie internally within a cluster. \n",
    "\n",
    "**Non-core samples** do not meet the minimum required neighboring points, but are still connected to a cluster defined by a core sample or samples. Hence these points lie on the edges of a cluster.\n",
    "\n",
    "**Outliers** are points that do not meet the distance criteria to a cluster nor minimum neighbors to form a new cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DBSCAN algorithm\n",
    "\n",
    "The DBSCAN algorithm proceeds iteratively through the points, determining via the distance measure and minimum samples specified whether points are core samples, edge samples, or outliers.\n",
    "\n",
    "Here is the pseudocode algorithm below, which we will be coding up ourselves:\n",
    "\n",
    "\n",
    "```\n",
    "DBSCAN(D, eps, MinPts) {\n",
    "   C = 0\n",
    "   for each point P in dataset D {\n",
    "      if P is visited\n",
    "         continue next point\n",
    "      mark P as visited\n",
    "      NeighborPts = regionQuery(P, eps)\n",
    "      if sizeof(NeighborPts) < MinPts\n",
    "         mark P as NOISE\n",
    "      else {\n",
    "         C = next cluster\n",
    "         expandCluster(P, NeighborPts, C, eps, MinPts)\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "expandCluster(P, NeighborPts, C, eps, MinPts) {\n",
    "   add P to cluster C\n",
    "   for each point P' in NeighborPts { \n",
    "      if P' is not visited {\n",
    "         mark P' as visited\n",
    "         NeighborPts' = regionQuery(P', eps)\n",
    "         if sizeof(NeighborPts') >= MinPts\n",
    "            NeighborPts = NeighborPts joined with NeighborPts'\n",
    "      }\n",
    "      if P' is not yet member of any cluster\n",
    "         add P' to cluster C\n",
    "   }\n",
    "}\n",
    "\n",
    "regionQuery(P, eps)\n",
    "   return all points within P's eps-neighborhood (including P)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DBSCAN in parts\n",
    "\n",
    "We can roll our own DBSCAN following the pseudcode above. Doing it piece by piece in parts will make it clear how the algorithm works.\n",
    "\n",
    "### 1. Create some clustered data\n",
    "\n",
    "sklearn has some nice data generation functions in its `sklearn.datasets` module. I've loaded a handful of them below. You can use them to create clustered data easily to test clustering algorithms.\n",
    "\n",
    "Generate clustered data and plot it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset generators:\n",
    "from sklearn.datasets import make_biclusters, make_blobs, make_circles, make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use one of the loaded data generaters to generate clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Make the skeleton of the DBSCAN class\n",
    "\n",
    "Start laying out the blueprint for how DBSCAN will work. We'll need to start out:\n",
    "\n",
    "1. An `__init__` function to initialize the class with the `eps` and `min_samples` arguments.\n",
    "- A (for now empty) `fit` function that will run DBSCAN on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dad6c746bae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "a = np.array([[1], [2, ][3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Writing the `fit` function (equivalent to the `DBSCAN` function in pseudocode)\n",
    "\n",
    "Our `fit` function will follow the logic of the `DBSCAN` function in the pseudocode above (re-pasted here). In general, when building classes, think about what variables are best suited to be class attributes. It takes practice to get a feel for it.\n",
    "\n",
    "```\n",
    "DBSCAN(D, eps, MinPts) {\n",
    "   C = 0\n",
    "   for each point P in dataset D {\n",
    "      if P is visited\n",
    "         continue next point\n",
    "      mark P as visited\n",
    "      NeighborPts = regionQuery(P, eps)\n",
    "      if sizeof(NeighborPts) < MinPts\n",
    "         mark P as NOISE\n",
    "      else {\n",
    "         C = next cluster\n",
    "         expandCluster(P, NeighborPts, C, eps, MinPts)\n",
    "      }\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Write the function to find neighbors\n",
    "\n",
    "We need to convert this function in the pseudocode to a class function:\n",
    "\n",
    "```\n",
    "regionQuery(P, eps)\n",
    "   return all points within P's eps-neighborhood (including P)\n",
    "```\n",
    "\n",
    "I've already named this `self.find_region_points(i)` so far, so we'll call it that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Write the function to expand the clusters.\n",
    "\n",
    "The final function (and the one that actually assigns our clusters) is defined by the pseudocode as:\n",
    "\n",
    "```\n",
    "expandCluster(P, NeighborPts, C, eps, MinPts) {\n",
    "   add P to cluster C\n",
    "   for each point P' in NeighborPts { \n",
    "      if P' is not visited {\n",
    "         mark P' as visited\n",
    "         NeighborPts' = regionQuery(P', eps)\n",
    "         if sizeof(NeighborPts') >= MinPts\n",
    "            NeighborPts = NeighborPts joined with NeighborPts'\n",
    "      }\n",
    "      if P' is not yet member of any cluster\n",
    "         add P' to cluster C\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "Essentially the function takes a point id, the neighboring point ids, the cluster number, minimum distance, and minimum points, and figures out based on those components what cluster a point should be in. \n",
    "\n",
    "I've already pre-named this function in the `fit` function to be `expand_cluster(i, neighbors)`. We only need to pass in the current point and neighboring points because we're storing all of the other information the function needs as class attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Plotting DBSCAN interactively\n",
    "\n",
    "We can look at how the `eps` and `min_samples` parameters affect DBSCAN's decisions about assigning clusters. This is also a good opportunity to go over how to make interactive visualizations with ipython widgets.\n",
    "\n",
    "### 1. Re-write the plotting function to accept cluster labels and color the points accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_clusters(X, labels):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Write a function that accepts `eps` and `min_samples` as keyword arguments, fits DBSCAN, and calls the plotting function\n",
    "\n",
    "Don't pass `X` in to the function. We will just use the \"global\" X defined in the jupyter notebook earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_plotter(eps=1.0, min_samples=5):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Make the \"interact\" function that creates the ipython widget\n",
    "\n",
    "Your interact function defines the sliders (or other inputs you want to be interactive) and then makes a call to `widgets.interact(function, *interactive objects)` where:\n",
    "\n",
    "- \"function\" is the function that takes the values coming out of the interactive slider objects (we wrote it just before: it takes `eps` and `min_samples`\n",
    "- The interactive objects in our case will be a `widgets.FloatSlider` for eps and a `widgets.IntSlider` for the min_samples.\n",
    "\n",
    "For more information see this handy notebook:\n",
    "\n",
    "https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Index.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_interact():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "<a name=\"more\"></a>\n",
    "### Additional Resources\n",
    "\n",
    "Check out Sklearn's implementaion of [DBSCAN](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)\n",
    "\n",
    "Check out a Hierarchical version of DBSCAN called [HDBSCAN](https://pypi.python.org/pypi/hdbscan/). This package has a fast implementation that performs faster than other Python clustering methods. This [Jupyter Notebook](http://nbviewer.jupyter.org/github/scikit-learn-contrib/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb) explains in lucid detail just how HDBSCAN works. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
