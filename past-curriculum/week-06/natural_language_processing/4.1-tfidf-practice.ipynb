{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Practice\n",
    "\n",
    "Today we will be taking a closer look at TFIDF as a descriptive measure of rare terms, and practicing some basic plots with TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries and setup code\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic example, revisited.\n",
    "\n",
    "To understand TFIDF is to use it at a basic level, again.  For our mini-practice today, we will revisit the cat, rat, and the bat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"I am a cat.\", \"I am a bat.\", \"I am a rat.\"] # which animal are you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorize your corpus using TfidfVectorizer and set to a variable called \"X\"\n",
    "1. Initialize TfidfVectorizer to a new variable.\n",
    "1. Set X to the return of fit_transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer to a new variable.\n",
    "\n",
    "# Set X to the return of fit_transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at your vectorized corpus, X, as an array or a dense matrix.\n",
    "What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intialize a new dataframe with an array from X.\n",
    "Also, set the columns to the TF-IDF vectorizer objects `.get_feature_names()` reference.  Without it, you won't be able to reference which word features correspond to which matrix column.\n",
    "\n",
    "Each row will coorespond to each document from the original corpus object.  Verify that each row matches the original dataset with the word features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup your dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregate your data with mean, median, min, max.  Plot each of your results with a \"bar\" or \"barh\" figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Refactor your existing code into a function.\n",
    "- Your method should accept a corpus object, a vectorizer type (tfidf or countvectorizer), and aggregate function parameter (string or function -- your choice!).\n",
    "- Your method should output a figure\n",
    "\n",
    "An example use case of your code would be:\n",
    "> ```python\n",
    ">  corpus = [\"I am a rat\", \"I am a cat\", \"I am a bat\"]\n",
    ">\n",
    ">  # TFIDF plot with max aggregation\n",
    ">  vectorize_and_plot(corpus, vectorizer=\"tfidf\", agg_func=\"max\")\n",
    ">  [your plot here] \n",
    ">\n",
    ">  # COUNT plot with max aggreagation\n",
    ">  vectorize_and_plot(corpus, vectorizer=\"count\", agg_func=\"max\")\n",
    ">  [your plot here] \n",
    ">  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use your function to compare CountVectorizer vs TfidfVectorizer \n",
    "- Use the original corpus object\n",
    "- THEN try using the new corpus object below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Original corpus\n",
    "# corpus = [\"I am a cat.\", \"I am a bat.\", \"I am a rat.\"] # which animal are you?\n",
    "\n",
    "## New corpus\n",
    "# corpus = [\"I am a cat.\", \"I am a bat.\", \"I am a rat.\", \"the cat is not a rat\", \"There is not a cat that sat\"] # which animal are you?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check out this awesome pipeline.\n",
    "- Fit the corpus object\n",
    "- Try to run a basic prediction\n",
    "\n",
    "_This is not a real-world probem but hopefully you get a sense of the basics of looking at text data, and it's application in sklearn._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73318551367331852"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# setup our data\n",
    "\n",
    "\"\"\" We use this list to filter which categories we want from our sample newsgroups dataset \"\"\"\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "training_data = fetch_20newsgroups(\n",
    "    subset       =  'train', \n",
    "    categories   =  categories,\n",
    "    shuffle      =  True, \n",
    "    random_state =  42,\n",
    "    remove       = ('headers', 'footers', 'quotes'))\n",
    "\n",
    "test_data = fetch_20newsgroups(\n",
    "    subset       =  'test', \n",
    "    categories   =  categories,\n",
    "    shuffle      =  True, \n",
    "    random_state =  42,\n",
    "    remove       =  ('headers', 'footers', 'quotes')\n",
    ")\n",
    "\n",
    "\"\"\" Our training data \"\"\"\n",
    "X_train = training_data.data\n",
    "y_train = training_data.target\n",
    "\n",
    "\"\"\" Our testing data\"\"\"\n",
    "X_test = test_data.data\n",
    "y_test = test_data.target\n",
    "\n",
    "# Rememver all that code needed to vectorize our text data before modeling?  \n",
    "# We still need to use it in order to do EDA and evalutate our dataset before we model. \n",
    "# DO NOT GET IN THE HABBIT OF MODELING WITHOUT EDA!\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),     # You will have questions about this\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    # ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "# Fit our data to the pipeline AS IF it were any other model like we've previously done in sklearn\n",
    "# Note:  X_train is literal text data, RAW format!\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reference the vectorized matrix from the \"model\" object cast from the Pipeline instance.\n",
    "Plot the vectorized data with aggregation.  Your previous function will work well if you refactor. \n",
    "\n",
    "_It's helpful to look at different subset classes to understand how each of the features could or may contribute to prediction.  To know which model to use, how it may perform, it's essential to look at your data in order to understand model selection well and confidently evaluate and report findings._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Here are some hints to jumpstart your work\n",
    "\n",
    "# 1. Inspect the pipeline object.  All of the \"steps\" whithin the pipeline are contained inside.\n",
    "pipeline.steps\n",
    "\n",
    "# 2. Use the 2nd step object, \"tfidf\", to get a reference to the object that can transform data\n",
    "# this will get \"TfidfTransformer\" object in the steps list ('tfidf', TfidfTransformer)\n",
    "step2_transformer = pipeline.steps[1][1] \n",
    "\n",
    "# 3. Use the step2_transformer to .fit_transform() and examine your training dataset with proper EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Update the pipeline to use only CountVectorizer.\n",
    "Also experiment different classification models:\n",
    "- KNN\n",
    "- Random Forrest"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
