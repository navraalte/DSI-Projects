{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Review : Algorithm Complexity, Statistics, SVD, Linear Regression\n",
    "---\n",
    "\n",
    "### Review : [Big O notation](https://www.youtube.com/watch?v=v4cd1O4zkGw)\n",
    "\n",
    "### Algorithmic Complexity of Operations on Basic Python Data structures\n",
    "\n",
    "What are the complexities of the following functions?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function 1\n",
    "def is_unique3 (alist)\n",
    "    aset = set(alist) #O(N): construct set from alist values\n",
    "    return len(aset) == len(alist)#O(1): 2 len (each O(1)) and == ints O(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given two lists my_list = [1,2,3,4,10] and your_list = ['a','b']\n",
    "What is the complexity of :\n",
    "1. Extending a list :  my_list.extend(your_list) #\n",
    "2. Constructing a list : my_list = list(4) #\n",
    "3. Copying a list : my_list.copy() #\n",
    "4. Look up via indexing : my_list[1]  #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given a dictionary super_heroes = {'batman': 'joker','superman': 'lex luthor', 'thor':'loki'}\n",
    "What is the complexity of :\n",
    "1. Deleting a key :\n",
    "    del super_heroes['thor']\n",
    "2. Store a new value :\n",
    "    super_heroes['wonder_woman'] = 'Aries'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Singular Value Decomposition\n",
    "\n",
    "\n",
    "#### Eigenvectors & Eigenvalues\n",
    "\n",
    "[Visual representation](http://setosa.io/ev/eigenvectors-and-eigenvalues/)\n",
    "\n",
    "An eigenvector is a vector whose direction remains unchanged when a linear transformation is applied to it. Consider the image below in which three vectors are shown. The green square is only drawn to illustrate the linear transformation that is applied to each of these three vectors.\n",
    "\n",
    "\n",
    "![eigenvectors](http://www.visiondummy.com/wp-content/uploads/2014/03/eigenvectors.png)\n",
    "Eigenvectors (red) do not change direction when a linear transformation (e.g. scaling) is applied to them. Other vectors (yellow) do.\n",
    "\n",
    "The transformation in this case is a simple scaling with factor 2 in the horizontal direction and factor 0.5 in the vertical direction, such that the transformation matrix A is defined as:\n",
    "\n",
    "A=\\begin{bmatrix} 2 & 0 \\\\ 0 & 0.5 \\end{bmatrix}.\n",
    "\n",
    "A vector v =(x,y) is then scaled by applying this transformation as v = A\\vec{v}. The above figure shows that the direction of some vectors (shown in red) is not affected by this linear transformation. These vectors are called eigenvectors of the transformation, and uniquely define the square matrix A. This unique, deterministic relation is exactly the reason that those vectors are called ‘eigenvectors’ (Eigen means ‘specific’ in German).\n",
    "\n",
    "In general, the eigenvector \\begin{equation*}\\vec{v}\\end{equation*} of a matrix A is the vector for which the following holds:\n",
    "\n",
    "(1)   \\begin{equation*} A \\vec{v} = \\lambda \\vec{v} \\end{equation*}\n",
    "\n",
    "where \\begin{equation*}\\lambda\\end{equation*} is a scalar value called the ‘eigenvalue’. \n",
    "\n",
    "#### Singular Value decomposition\n",
    "\n",
    "Singular value decomposition is essentially trying to reduce a rank R matrix to a rank K matrix.\n",
    "\n",
    "But what does this mean?\n",
    "\n",
    "It means that we can take a list of  R unique vectors, and approximate them as a linear combination of K unique vectors.\n",
    "\n",
    "The SVD of a matrix A is :\n",
    "  \\begin{equation} {A} = {U} {\\boldsymbol {\\Sigma }} {V} ^{T}\\end{equation}\n",
    "\n",
    "\n",
    "What's so Special about SVD?\n",
    "\n",
    "Singular Value Decomposition has two wonderful properties that make it very helpful and important for our work. First, it exists for any and all matrices: large, small, square, rectangular,sparse and dense.<br>\n",
    "\n",
    "The next helpful property is the optimality property. This property basically tells us that, if we would like to find a rank-k approximation of our matrix, the best one can be found using singular value decomposition.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Review : \n",
    "\n",
    "\n",
    "#### Hypothesis testing : \n",
    "\n",
    "A hypothesis test is a statistical test that is used to determine whether there is enough evidence in a sample of data to infer that a certain condition is true for the entire population.\n",
    "\n",
    "A hypothesis test examines two opposing hypotheses about a population: the null hypothesis and the alternative hypothesis. The null hypothesis is the statement being tested. Usually the null hypothesis is a statement of \"no effect\" or \"no difference\". The alternative hypothesis is the statement you want to be able to conclude is true.\n",
    "\n",
    "Based on the sample data, the test determines whether to reject the null hypothesis. You use a p-value, to make the determination. If the p-value is less than or equal to the level of significance, which is a cut-off point that you define, then you can reject the null hypothesis.\n",
    "\n",
    "Steps :\n",
    "- Form a null and alternative hypothesis\n",
    "- Select a significance level, alpha (usually 5%)\n",
    "- Select a statistical test\n",
    "- Calculate the appropriate statistic\n",
    "- Compare the p-value with alpha\n",
    "- If the p-value > alpha, then we fail to reject the null hypothesis\n",
    "- If the p-value <= alpha, then we reject the null hypothesis in favor of the alternative hypothesis\n",
    "\n",
    "Examples of questions you can answer with a hypothesis test include:\n",
    "- Does the mean height of undergraduate women differ from 66 inches?\n",
    "- Do male and female undergraduates differ in height?\n",
    "\n",
    "##### p values : \n",
    "The probability that the Null hypothesis is true. A low p values indicates that the null hypothesis is unlikely to be true.\n",
    "\n",
    "##### Type I & Type II\n",
    "\n",
    "When you do a hypothesis test, two types of errors are possible: type I and type II. The risks of these two errors are inversely related and determined by the level of significance and the power for the test. Therefore, you should determine which error has more severe consequences for your situation before you define their risks.\n",
    "\n",
    "![](https://effectsizefaq.files.wordpress.com/2010/05/type-i-and-type-ii-errors.jpg)\n",
    "\n",
    "No hypothesis test is 100% certain. Because the test is based on probabilities, there is always a chance of drawing an incorrect conclusion.<br>\n",
    "\n",
    "__Type I error__\n",
    "When the null hypothesis is true and you reject it, you make a type I error. The probability of making a type I error is α, which is the level of significance you set for your hypothesis test. An α of 0.05 indicates that you are willing to accept a 5% chance that you are wrong when you reject the null hypothesis. To lower this risk, you must use a lower value for α. However, using a lower value for alpha means that you will be less likely to detect a true difference if one really exists.\n",
    "\n",
    "__Type II error__\n",
    "When the null hypothesis is false and you fail to reject it, you make a type II error. The probability of making a type II error is β, which depends on the power of the test. You can decrease your risk of committing a type II error by ensuring your test has enough power. You can do this by ensuring your sample size is large enough to detect a practical difference when one truly exists.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Confidence intervals : \n",
    "\n",
    "The general idea of any confidence interval is that we have an unknown value in the population and we want to get a good estimate of its value.\n",
    "\n",
    "\n",
    "To compute a confidence interval, you need three pieces of data:\n",
    "\n",
    "- Confidence Level: usually 95%.\n",
    "- Variability: if there is more variation in a population, each sample taken will fluctuate more and wider the confidence interval. The variability of the population is estimated using the standard deviation from the sample.\n",
    "- Sample size: without lowering the confidence level, the sample size can control the width of a confidence interval, having an inverse square root relationship to it.\n",
    "\n",
    "\n",
    "The mean (for continuous data) or proportion (for binary data)\n",
    "The standard deviation, which describes how dispersed the data is around the average\n",
    "The sample size\n",
    "\n",
    "\n",
    "\n",
    "#### T-test \n",
    "\n",
    "A t-test is commonly used to determine whether the mean of a population significantly differs from a specific value (called the hypothesized mean) or from the mean of another population.\n",
    "\n",
    "For example, a 1-sample t-test could test whether the mean waiting time for all patients in a medical clinic is greater than a target wait time of, say, 15 minutes, based on a random sample of patients.\n",
    "\n",
    "anatomy t - test. To determine whether the difference is statistically significant, the t-test calculates a t-value. (The p-value is obtained directly from this t-value.) \n",
    "    \n",
    "![](http://cdn2.content.compendiumblog.com/uploads/user/458939f4-fe08-4dbc-b271-efca0f5a2682/ba6a552e-3bc0-4eed-9c9a-eae3ade49498/Image/d7a6446b0943390f1dc89e567169f852/ttest_formula_3.jpg)\n",
    "\n",
    "The 2-sample t-test takes your sample data from two groups and boils it down to the t-value. The process is very similar to the 1-sample t-test, and you can still use the analogy of the signal-to-noise ratio. Unlike the paired t-test, the 2-sample t-test requires independent groups for each sample.\n",
    "\n",
    "The formula is below, and then some discussion.\n",
    "\n",
    "formula to calculate t for a 2-sample t-test\n",
    "![](http://www.stat.yale.edu/Courses/1997-98/101/tstat2.gif)\n",
    "\n",
    "For the 2-sample t-test, the numerator is again the signal, which is the difference between the means of the two samples. For example, if the mean of group 1 is 10, and the mean of group 2 is 4, the difference is 6.\n",
    "\n",
    "The default null hypothesis for a 2-sample t-test is that the two groups are equal. You can see in the equation that when the two groups are equal, the difference (and the entire ratio) also equals zero. As the difference between the two groups grows in either a positive or negative direction, the signal becomes stronger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear Regression\n",
    "\n",
    "Simple linear regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables:\n",
    "\n",
    "- One variable, denoted x, is regarded as the predictor, explanatory, or independent variable.\n",
    "- The other variable, denoted y, is regarded as the response, outcome, or dependent variable.\n",
    "\n",
    "Simple linear regression gets its adjective \"simple,\" because it concerns the study of only one predictor variable. In contrast, multiple linear regression, which we study later in this course, gets its adjective \"multiple,\" because it concerns the study of two or more predictor variables.\n",
    "\n",
    "It takes the following form:<br>\n",
    "$y = \\beta_0 + \\beta_1x$ <br>\n",
    "\n",
    "What does each term represent?\n",
    "-  $y$ is the response\n",
    "-  $x$ is the feature\n",
    "-  $\\beta_0$ is the intercept\n",
    "-  $\\beta_1$ is the coefficient for x\n",
    "\n",
    "\n",
    "Together, $\\beta_0$ and $\\beta_1$ are called the model coefficients. To create your model, you must \"learn\" the values of these coefficients. And once we've learned these coefficients, we can use the model to predict Sales!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Estimating (\"Learning\") Model Coefficients\n",
    "Generally speaking, coefficients are estimated using the least squares criterion, which means we are find the line (mathematically) which minimizes the sum of squared residuals (or \"sum of squared errors\"):\n",
    "\n",
    "![](https://github.com/justmarkham/DAT4/raw/068d887e4be2eedb1b958b345ae097153f762d75/notebooks/08_estimating_coefficients.png)\n",
    "\n",
    "\n",
    "What elements are present in the diagram?\n",
    "- The black dots are the observed values of x and y.\n",
    "- The blue line is our least squares line.\n",
    "- The red lines are the residuals, which are the distances between the observed values and the least squares line.\n",
    "How do the model coefficients relate to the least squares line?\n",
    "-  $\\beta_0$ is the intercept (the value of $y$ when $x$=0)\n",
    "-  $\\beta_1$ is the slope (the change in $y$ divided by change in $x$)\n",
    "Here is a graphical depiction of those calculations:\n",
    "\n",
    "![](https://github.com/justmarkham/DAT4/raw/068d887e4be2eedb1b958b345ae097153f762d75/notebooks/08_slope_intercept.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it relates to model coefficients, here is the conventional hypothesis test:\n",
    "- null hypothesis: There is no relationship between Independent Variable ads and Dependent variable(s) (and thus $\\beta_1$ equals zero)\n",
    "- alternative hypothesis: There is a relationship between Independent variable ads and dependent variable(and thus $\\beta_1$ is not equal to zero)\n",
    "\n",
    "\n",
    "How do we test this hypothesis? Intuitively, we reject the null (and thus believe the alternative) if the 95% confidence interval does not include zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How Well Does the Model Fit the data?\n",
    "The most common way to evaluate the overall fit of a linear model is by the R-squared value. R-squared is the proportion of variance explained, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the null model. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
    "R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. Here's an example of what R-squared \"looks like\":\n",
    "\n",
    "![](https://github.com/justmarkham/DAT4/raw/068d887e4be2eedb1b958b345ae097153f762d75/notebooks/08_r_squared.png)\n",
    "\n",
    "You can see that the blue line explains some of the variance in the data (R-squared=0.54), the green line explains more of the variance (R-squared=0.64), and the red line fits the training data even further (R-squared=0.66). (Does the red line look like it's overfitting?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
