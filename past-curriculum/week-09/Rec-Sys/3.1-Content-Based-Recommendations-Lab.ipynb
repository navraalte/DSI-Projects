{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 10px\">\n",
    "\n",
    "# Content Based Recommendations Lab\n",
    "Week 9 | Lesson 3.1\n",
    "\n",
    "\n",
    "![](http://aerofarms.com/wp-content/uploads/2015/04/NYTimes-banner.jpg)\n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "\n",
    "In this lab you will create a content based recommender for New York Times articles. This recommender is an example of a very simple data product. You will follow the same proceedure outlined in this [Medium article](https://medium.com/data-lab/how-we-used-data-to-suggest-tags-for-your-story-a120076d0bb6#.4vu7uby9z) in order to build your very own content based recommender. ![](https://s-media-cache-ak0.pinimg.com/236x/1d/cd/4e/1dcd4e0152a3692314f65a1aafb53982.jpg) However, we will not be recommending tags. Instead we'll be recommending new articles that a user should read based on the article that they are currently reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain your approach \n",
    "\n",
    "You are in a technical job interview. \n",
    "\n",
    "Explain in your own words to your interviewer how the content based recommendation approach works. Specifically, explianed how you will apply this approach to recommend readers new NYT articles to read based on the article they are currently reading. \n",
    "\n",
    "**Hint: ** Read the Medium article and adapt their approach for your purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "1. Inspect your data\n",
    "2. Identify the time range in which these articles were published\n",
    "3. Can you think of any major domestic events happening in this time range?\n",
    "4. Count the number of articles from each section\n",
    "5. Will the section name imbalance bias our recommendations? \n",
    "6. What do you think is the appropriate response to the section name imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import relavent packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "data_path = \"./datasets/NYT-articles.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inspect your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identify the time range in which these articles were published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Can you think of any major domestic events happening in this time range?\n",
    "\n",
    ">Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Count the number of articles in each section\n",
    "\n",
    "**Hint:** Make your life easier and use Counter from collections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering \n",
    "\n",
    "Here you will split your data into a \"train\" and \"test\". As well as select a metric in which to measure the similarity between articles. Think of the \"train\" set as the corpus. Think of the \"test\" set as the NYT articles that users are currently reading. \n",
    "\n",
    "### 5.1 Split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# move articles to an array\n",
    "\n",
    "# move article section names to an array\n",
    "\n",
    "# move article web_urls to an array\n",
    "\n",
    "# shuffle these three arrays \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the shuffled articles into two arrays\n",
    "\n",
    "\n",
    "# one will have all but the last 10 articles -- think of this as your training set/corpus \n",
    "\n",
    "# the other will have those last 10 articles -- think of this as your test set/corpus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 2 Text Vectorizers\n",
    "\n",
    "You're still in a job interview. Your interviewer asks you to respond to the follow:\n",
    "\n",
    "**Choose CountVectorizer or TFIDF as your text vectorizer. Which do you choose?**\n",
    "\n",
    "> Write your anser here\n",
    "\n",
    "**Justify your choice**\n",
    "\n",
    "> Write your anser here\n",
    "\n",
    "**Explain why you didn't choose the other option **\n",
    "\n",
    "> Write your anser here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your interviewer asks you to respond to the follow:\n",
    "\n",
    "**Choose to use or not to use stop words. Which do you choose?**\n",
    "\n",
    "> Write your anser here\n",
    "\n",
    "**Justify your choice**\n",
    "\n",
    "> Write your anser here\n",
    "\n",
    "**Explain why you didn't choose the other option **\n",
    "\n",
    "> Write your anser here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate your vectorizor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the vectorizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform both article splits \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Similarity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're still in a job interview. \n",
    "Your logic and reasoning powers are still being evaluated. \n",
    "Your interviewer asks you to respond to the follow:\n",
    "\n",
    "**Hint: ** You might find these resources helpful: [Jaccard](https://en.wikipedia.org/wiki/Jaccard_index) , [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) \n",
    "\n",
    "\n",
    "**Choose the Jaccard or Cosine similarity metric to find the similarity between your train and test articles. Which do you choose?**\n",
    "\n",
    "> Write your anser here\n",
    "\n",
    "**Justify your choice**\n",
    "\n",
    "> Write your anser here\n",
    "\n",
    "**Explain why you didn't choose the other option **\n",
    "\n",
    "> Write your anser here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacard Metric\n",
    "If you choose to use the Jacard metric, you can import that metric from sklearn. \n",
    "\n",
    "#### Cosine Metric\n",
    "If you choose to use the Cosine metric, apply the same approach to calculating similarities as was done in the Medium article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Builidng a Content Based Recommder\n",
    "\n",
    "This section is where the magic happends. Here you will build a function that outputs the top n articles to recommend to your user based on the similarity scores between the article they're currently reading and all other articles in the corpus (i.e. \"train\" data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_n_rec_articles(X_train_vectorized, X_train, test_article, X_train_sections, X_train_urls, n = 5):\n",
    "    '''This function calculates similarity scores bewteen a document and a corpus\n",
    "    \n",
    "       INPUT: vectorized document corpus, 2D array\n",
    "              text document corpus, 2D array\n",
    "              user article, 1D array\n",
    "              article section names, 1D array\n",
    "              article URLs, 1D array\n",
    "              number of articles to recommend, int\n",
    "              \n",
    "       OUTPUT: top n recommendations, 1D array\n",
    "               top n corresponding section names, 1D array\n",
    "               top n corresponding URLs, 1D array\n",
    "               similarity scores bewteen user article and entire corpus, 1D array\n",
    "              '''\n",
    "    # calculate similarity between the corpus (i.e. the \"test\" data) and the user's article\n",
    "\n",
    "    # get sorted similairty score indicies \n",
    "\n",
    "    # get sorted similarity socres\n",
    "\n",
    "    # get top n most similar documents\n",
    "\n",
    "    # get top n corresponding document section names\n",
    "\n",
    "    # get top n corresponding urls\n",
    "    \n",
    "    # return recommendations and corresponding article meta-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick an article from the \"test\" set\n",
    "# treat this as the article that the user is currently reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return the top n most similar articles as recommendations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interrogate the results \n",
    "\n",
    "Now that you have recommended articles for the user to read (based on what they are currently reading) check to see if the results make sense. \n",
    "\n",
    "Compare the user's article and corresponding section name with the recommended articles and corresponding section names. \n",
    "\n",
    "Also take a look at the similarity scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# analyze similarity scores - what do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user's article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user's article's section name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corresponding section names for top n recs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top n article recs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corresonding URLs for top n recs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Additoinal Resources \n",
    "\n",
    "http://infolab.stanford.edu/~ullman/mmds/ch9.pdf\n",
    "\n",
    "http://benanne.github.io/2014/08/05/spotify-cnns.html\n",
    "\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.25.5743&rep=rep1&type=pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
